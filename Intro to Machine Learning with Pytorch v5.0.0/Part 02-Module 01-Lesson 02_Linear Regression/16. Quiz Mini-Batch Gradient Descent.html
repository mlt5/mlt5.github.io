<!-- udacity2.0 -->
<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>Quiz: Mini-Batch Gradient Descent</title>
  <link rel="stylesheet" href="../assets/css/bootstrap.min.css">
  <link rel="stylesheet" href="../assets/css/plyr.css">
  <link rel="stylesheet" href="../assets/css/katex.min.css">
  <link rel="stylesheet" href="../assets/css/jquery.mCustomScrollbar.min.css">
  <link rel="stylesheet" href="../assets/css/styles.css">
  <link rel="shortcut icon" type="image/png" href="../assets/img/udacimak.png" />
</head>

<body>
  <div class="wrapper">
    <nav id="sidebar">
  <div class="sidebar-header">
    <h3>Linear Regression</h3>
  </div>

  <ul class="sidebar-list list-unstyled CTAs">
    <li>
      <a href="../index.html" class="article">Back to Home</a>
    </li>
  </ul>

  <ul class="sidebar-list list-unstyled components">
    <li class="">
      <a href="01. Intro.html">01. Intro</a>
    </li>
    <li class="">
      <a href="02. Quiz Housing Prices.html">02. Quiz: Housing Prices</a>
    </li>
    <li class="">
      <a href="03. Solution Housing Prices.html">03. Solution: Housing Prices</a>
    </li>
    <li class="">
      <a href="04. Fitting a Line Through Data.html">04. Fitting a Line Through Data</a>
    </li>
    <li class="">
      <a href="05. Moving a Line.html">05. Moving a Line</a>
    </li>
    <li class="">
      <a href="06. Absolute Trick.html">06. Absolute Trick</a>
    </li>
    <li class="">
      <a href="07. Square Trick.html">07. Square Trick</a>
    </li>
    <li class="">
      <a href="08. Quiz Absolute and Square Trick.html">08. Quiz: Absolute and Square Trick</a>
    </li>
    <li class="">
      <a href="09. Gradient Descent.html">09. Gradient Descent</a>
    </li>
    <li class="">
      <a href="10. Mean Absolute Error.html">10. Mean Absolute Error</a>
    </li>
    <li class="">
      <a href="11. Mean Squared Error.html">11. Mean Squared Error</a>
    </li>
    <li class="">
      <a href="12. Quiz Mean Absolute &amp; Squared Errors.html">12. Quiz: Mean Absolute &amp; Squared Errors</a>
    </li>
    <li class="">
      <a href="13. Minimizing Error Functions.html">13. Minimizing Error Functions</a>
    </li>
    <li class="">
      <a href="14. Mean vs Total Error.html">14. Mean vs Total Error</a>
    </li>
    <li class="">
      <a href="15. Mini-batch Gradient Descent.html">15. Mini-batch Gradient Descent</a>
    </li>
    <li class="">
      <a href="16. Quiz Mini-Batch Gradient Descent.html">16. Quiz: Mini-Batch Gradient Descent</a>
    </li>
    <li class="">
      <a href="17. Absolute Error vs Squared Error.html">17. Absolute Error vs Squared Error</a>
    </li>
    <li class="">
      <a href="18. Linear Regression in scikit-learn.html">18. Linear Regression in scikit-learn</a>
    </li>
    <li class="">
      <a href="19. Higher Dimensions.html">19. Higher Dimensions</a>
    </li>
    <li class="">
      <a href="20. Multiple Linear Regression.html">20. Multiple Linear Regression</a>
    </li>
    <li class="">
      <a href="21. Closed Form Solution.html">21. Closed Form Solution</a>
    </li>
    <li class="">
      <a href="22. (Optional) Closed form Solution Math.html">22. (Optional) Closed form Solution Math</a>
    </li>
    <li class="">
      <a href="23. Linear Regression Warnings.html">23. Linear Regression Warnings</a>
    </li>
    <li class="">
      <a href="24. Polynomial Regression.html">24. Polynomial Regression</a>
    </li>
    <li class="">
      <a href="25. Quiz Polynomial Regression.html">25. Quiz: Polynomial Regression</a>
    </li>
    <li class="">
      <a href="26. Regularization.html">26. Regularization</a>
    </li>
    <li class="">
      <a href="27. Quiz Regularization.html">27. Quiz: Regularization</a>
    </li>
    <li class="">
      <a href="28. Feature Scaling.html">28. Feature Scaling</a>
    </li>
    <li class="">
      <a href="29. Outro.html">29. Outro</a>
    </li>
  </ul>

  <ul class="sidebar-list list-unstyled CTAs">
    <li>
      <a href="../index.html" class="article">Back to Home</a>
    </li>
  </ul>
</nav>

    <div id="content">
      <header class="container-fluild header">
        <div class="container">
          <div class="row">
            <div class="col-12">
              <div class="align-items-middle">
                <button type="button" id="sidebarCollapse" class="btn btn-toggle-sidebar">
                  <div></div>
                  <div></div>
                  <div></div>
                </button>

                <h1 style="display: inline-block">16. Quiz: Mini-Batch Gradient Descent</h1>
              </div>
            </div>
          </div>
        </div>
      </header>

      <main class="container">
        <div class="row">
          <div class="col-12">
            <div class="ud-atom">
  <h3></h3>
  <div>
  <p><strong>Programming Quiz for "Mini-Batch Gradient Descent"</strong></p>
<h2 id="mini-batch-gradient-descent-quiz">Mini-Batch Gradient Descent Quiz</h2>
<p>In this quiz, you'll be given the following sample dataset (as in data.csv), and your goal is to write a function that executes mini-batch gradient descent to find a best-fitting regression line. You might consider looking into numpy's <code>matmul</code> function for this!</p>
</div>

</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <figure class="figure">
    <img src="img/l2-gradient-descent-data.png" alt="" class="img img-fluid">
    <figcaption class="figure-caption">
      
    </figcaption>
  </figure>
</div>


</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>

  <h4>Start Quiz:</h4>
  <div>
  <div class="nav nav-tabs nav-fill" role="tablist" id="question-tabs">
    <a href="#613162-batch_graddesc-py" class="nav-item nav-link  active show" id="tab-613162-batch_graddesc-py" data-toggle="tab" role="tab"
      aria-controls="613162-batch_graddesc-py" aria-selected="true">batch_graddesc.py</a>
    <a href="#613162-data-csv" class="nav-item nav-link " id="tab-613162-data-csv" data-toggle="tab" role="tab"
      aria-controls="613162-data-csv" aria-selected="false">data.csv</a>
    <a href="#613162-solution-py" class="nav-item nav-link " id="tab-613162-solution-py" data-toggle="tab" role="tab"
      aria-controls="613162-solution-py" aria-selected="false">solution.py</a>
  </div>

  <div class="tab-content" style="padding: 20px 0;" id="question-tab-contents">
    <div class="tab-pane  active show" id="613162-batch_graddesc-py" aria-labelledby="tab-613162-batch_graddesc-py" role="tabpanel">
      <pre><code></code>import numpy as np
# Setting a random seed, feel free to change it and see different solutions.
np.random.seed(42)


# TODO: Fill in code in the function below to implement a gradient descent
# step for linear regression, following a squared error rule. See the docstring
# for parameters and returned variables.
def MSEStep(X, y, W, b, learn_rate &#x3D; 0.005):
    &quot;&quot;&quot;
    This function implements the gradient descent step for squared error as a
    performance metric.
    
    Parameters
    X : array of predictor features
    y : array of outcome values
    W : predictor feature coefficients
    b : regression function intercept
    learn_rate : learning rate

    Returns
    W_new : predictor feature coefficients following gradient descent step
    b_new : intercept following gradient descent step
    &quot;&quot;&quot;
    
    # Fill in code
    
    return W_new, b_new


# The parts of the script below will be run when you press the &quot;Test Run&quot;
# button. The gradient descent step will be performed multiple times on
# the provided dataset, and the returned list of regression coefficients
# will be plotted.
def miniBatchGD(X, y, batch_size &#x3D; 20, learn_rate &#x3D; 0.005, num_iter &#x3D; 25):
    &quot;&quot;&quot;
    This function performs mini-batch gradient descent on a given dataset.

    Parameters
    X : array of predictor features
    y : array of outcome values
    batch_size : how many data points will be sampled for each iteration
    learn_rate : learning rate
    num_iter : number of batches used

    Returns
    regression_coef : array of slopes and intercepts generated by gradient
      descent procedure
    &quot;&quot;&quot;
    n_points &#x3D; X.shape[0]
    W &#x3D; np.zeros(X.shape[1]) # coefficients
    b &#x3D; 0 # intercept
    
    # run iterations
    regression_coef &#x3D; [np.hstack((W,b))]
    for _ in range(num_iter):
        batch &#x3D; np.random.choice(range(n_points), batch_size)
        X_batch &#x3D; X[batch,:]
        y_batch &#x3D; y[batch]
        W, b &#x3D; MSEStep(X_batch, y_batch, W, b, learn_rate)
        regression_coef.append(np.hstack((W,b)))
    
    return regression_coef


if __name__ &#x3D;&#x3D; &quot;__main__&quot;:
    # perform gradient descent
    data &#x3D; np.loadtxt(&#x27;data.csv&#x27;, delimiter &#x3D; &#x27;,&#x27;)
    X &#x3D; data[:,:-1]
    y &#x3D; data[:,-1]
    regression_coef &#x3D; miniBatchGD(X, y)
    
    # plot the results
    import matplotlib.pyplot as plt
    
    plt.figure()
    X_min &#x3D; X.min()
    X_max &#x3D; X.max()
    counter &#x3D; len(regression_coef)
    for W, b in regression_coef:
        counter -&#x3D; 1
        color &#x3D; [1 - 0.92 ** counter for _ in range(3)]
        plt.plot([X_min, X_max],[X_min * W + b, X_max * W + b], color &#x3D; color)
    plt.scatter(X, y, zorder &#x3D; 3)
    plt.show()</code></pre>
    </div>
    <div class="tab-pane " id="613162-data-csv" aria-labelledby="tab-613162-data-csv" role="tabpanel">
      <pre><code></code>-0.72407,2.23863
-2.40724,-0.00156
2.64837,3.01665
0.36092,2.31019
0.67312,2.05950
-0.45460,1.24736
2.20168,2.82497
1.15605,2.21802
0.50694,1.43644
-0.85952,1.74980
-0.59970,1.63259
1.46804,2.43461
-1.05659,1.02226
1.29177,3.11769
-0.74565,0.81194
0.15033,2.81910
-1.49627,0.53105
-0.72071,1.64845
0.32924,1.91416
-0.28053,2.11376
-1.36115,1.70969
0.74678,2.92253
0.10621,3.29827
0.03256,1.58565
-0.98290,2.30455
-1.15661,1.79169
0.09024,1.54723
-1.03816,1.06893
-0.00604,1.78802
0.16278,1.84746
-0.69869,1.58732
1.03857,1.94799
-0.11783,3.09324
-0.95409,1.86155
-0.81839,1.88817
-1.28802,1.39474
0.62822,1.71526
-2.29674,1.75695
-0.85601,1.12981
-1.75223,1.67000
-1.19662,0.66711
0.97781,3.11987
-1.17110,0.56924
0.15835,2.28231
-0.58918,1.23798
-1.79678,1.35803
-0.95727,1.75579
0.64556,1.91470
0.24625,2.33029
0.45917,3.25263
1.21036,2.07602
-0.60116,1.54254
0.26851,2.79202
0.49594,1.96178
-2.67877,0.95898
0.49402,1.96690
1.18643,3.06144
-0.17741,1.85984
0.57938,1.82967
-2.14926,0.62285
2.27700,3.63838
-1.05695,1.11807
1.68288,2.91735
-1.53513,1.99668
0.00099,1.76149
0.45520,2.31938
-0.37855,0.90172
1.35638,3.49432
0.01763,1.87838
2.21725,2.61171
-0.44442,2.06623
0.89583,3.04041
1.30499,2.42824
0.10883,0.63190
1.79466,2.95265
-0.00733,1.87546
0.79862,3.44953
-0.12353,1.53740
-1.34999,1.59958
-0.67825,1.57832
-0.17901,1.73312
0.12577,2.00244
1.11943,2.08990
-3.02296,1.09255
0.64965,1.28183
1.05994,2.32358
0.53360,1.75136
-0.73591,1.43076
-0.09569,2.81376
1.04694,2.56597
0.46511,2.36401
-0.75463,2.30161
-0.94159,1.94500
-0.09314,1.87619
-0.98641,1.46602
-0.92159,1.21538
0.76953,2.39377
0.03283,1.55730
-1.07619,0.70874
0.20174,1.76894</code></pre>
    </div>
    <div class="tab-pane " id="613162-solution-py" aria-labelledby="tab-613162-solution-py" role="tabpanel">
      <pre><code></code>def MSEStep(X, y, W, b, learn_rate &#x3D; 0.001):
    &quot;&quot;&quot;
    This function implements the gradient descent step for squared error as a
    performance metric.
    
    Parameters
    X : array of predictor features
    y : array of outcome values
    W : predictor feature coefficients
    b : regression function intercept
    learn_rate : learning rate

    Returns
    W_new : predictor feature coefficients following gradient descent step
    b_new : intercept following gradient descent step
    &quot;&quot;&quot;
    
    # compute errors
    y_pred &#x3D; np.matmul(X, W) + b
    error &#x3D; y - y_pred
    
    # compute steps
    W_new &#x3D; W + learn_rate * np.matmul(error, X)
    b_new &#x3D; b + learn_rate * error.sum()
    return W_new, b_new</code></pre>
    </div>
  </div>
</div>



</div>


</div>
<div class="divider"></div>
          </div>

          <div class="col-12">
            <p class="text-right">
              <a href="17. Absolute Error vs Squared Error.html" class="btn btn-outline-primary mt-4" role="button">Next Concept</a>
            </p>
          </div>
        </div>
      </main>

      <footer class="footer">
        <div class="container">
          <div class="row">
            <div class="col-12">
              <p class="text-center">
                <a href="https://us-udacity.github.io/" target="_blank">【udacity2.0 】If you need more courses, please add wechat：udacity6</a>
              </p>
            </div>
          </div>
        </div>
      </footer>
    </div>
  </div>


  <script src="../assets/js/jquery-3.3.1.min.js"></script>
  <script src="../assets/js/plyr.polyfilled.min.js"></script>
  <script src="../assets/js/bootstrap.min.js"></script>
  <script src="../assets/js/jquery.mCustomScrollbar.concat.min.js"></script>
  <script src="../assets/js/katex.min.js"></script>
  <script>
    // Initialize Plyr video players
    const players = Array.from(document.querySelectorAll('video')).map(p => new Plyr(p));

    // render math equations
    let elMath = document.getElementsByClassName('mathquill');
    for (let i = 0, len = elMath.length; i < len; i += 1) {
      const el = elMath[i];

      katex.render(el.textContent, el, {
        throwOnError: false
      });
    }

    // this hack will make sure Bootstrap tabs work when using Handlebars
    if ($('#question-tabs').length && $('#user-answer-tabs').length) {
      $("#question-tabs a.nav-link").on('click', function () {
        $("#question-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
      $("#user-answer-tabs a.nav-link").on('click', function () {
        $("#user-answer-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
    } else {
      $("a.nav-link").on('click', function () {
        $(".tab-pane").hide();
        $($(this).attr("href")).show();
      });
    }

    // side bar events
    $(document).ready(function () {
      $("#sidebar").mCustomScrollbar({
        theme: "minimal"
      });

      $('#sidebarCollapse').on('click', function () {
        $('#sidebar, #content').toggleClass('active');
        $('.collapse.in').toggleClass('in');
        $('a[aria-expanded=true]').attr('aria-expanded', 'false');
      });

      // scroll to first video on page loading
      if ($('video').length) {
        $('html,body').animate({ scrollTop: $('div.plyr').prev().offset().top});
      }

      // auto play first video: this may not work with chrome/safari due to autoplay policy
      if (players && players.length > 0) {
        players[0].play();
      }

      // scroll sidebar to current concept
      const currentInSideBar = $( "ul.sidebar-list.components li a:contains('16. Quiz: Mini-Batch Gradient Descent')" )
      currentInSideBar.css( "text-decoration", "underline" );
      $("#sidebar").mCustomScrollbar('scrollTo', currentInSideBar);
    });
  </script>
</body>

</html>
