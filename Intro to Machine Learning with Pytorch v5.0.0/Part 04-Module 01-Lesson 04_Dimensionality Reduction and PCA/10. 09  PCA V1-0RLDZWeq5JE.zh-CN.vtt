WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:03.765
PCA通常用于高维数据

00:00:03.765 --> 00:00:06.845
图像是一种高维数据

00:00:06.844 --> 00:00:11.814
在这个例子中 我们将看到一个非常常见的用于识别手写数字的情况

00:00:11.814 --> 00:00:17.434
图像数据的一个典型例子是 MNIST 数据集

00:00:17.434 --> 00:00:23.839
它在20世纪90年代末由微软、谷歌和纽约大学的研究人员开源

00:00:23.839 --> 00:00:28.524
我已在下面的 notebook 中链接了有关此数据集的更多信息

00:00:28.524 --> 00:00:31.174
首先 让我们导入要用到的库 

00:00:31.175 --> 00:00:34.130
然后对我们来说读入数据集很重要

00:00:34.130 --> 00:00:39.130
在本例中 我们将读取位于训练集中的 4.2万个图像 

00:00:39.130 --> 00:00:40.880
测试集包含

00:00:40.880 --> 00:00:44.520
另外的 2.8万个图像 现在我们还不能使用这些图像 

00:00:44.520 --> 00:00:47.085
然后我们可以查看这个数据集的头部

00:00:47.085 --> 00:00:49.820
我们也可以看看描述

00:00:49.820 --> 00:00:56.280
在本例中 我们可以看到第一列是类标签列 
每个标签表示一个范围是 0-9 的手写数字

00:00:56.280 --> 00:01:00.760
所以 这是 1 的图像 这是 0 的图像 

00:01:00.759 --> 00:01:03.184
1 的图像 4 的图像

00:01:03.185 --> 00:01:05.504
然后 你看这边 

00:01:05.504 --> 00:01:09.589
用范围是 0 到 255 之间的值

00:01:09.590 --> 00:01:14.600
来指示图像的某个特定像素的灰度 然后看一下描述 

00:01:14.599 --> 00:01:17.689
最后这里似乎有些缺失值

00:01:17.689 --> 00:01:20.504
所以 我现在要用零来填充

00:01:20.504 --> 00:01:23.524
看起来它们在像素的某个角落

00:01:23.525 --> 00:01:25.190
根据我们对数据的了解 

00:01:25.189 --> 00:01:29.079
让我们把标签和图像分开 把图像放到它们自己的矩阵中

00:01:29.079 --> 00:01:31.459
所以在这里我去掉了标签

00:01:31.459 --> 00:01:35.524
现在让我们用这个帮助函数看看图像是什么样子

00:01:35.525 --> 00:01:39.885
你可以从本视频下方的 notebook 中获取此帮助程序

00:01:39.885 --> 00:01:42.170
输入 100 我是说 

00:01:42.170 --> 00:01:44.644
你能给我看前 100张照片吗 ?

00:01:44.644 --> 00:01:46.219
如果我们看这个 

00:01:46.219 --> 00:01:49.344
有一些图像 很容易看出他们是什么数字

00:01:49.344 --> 00:01:50.885
这看起来像一个 1 

00:01:50.885 --> 00:01:54.505
一个 0  很明显是 8 和 9 

00:01:54.504 --> 00:01:57.289
但是还有其他的图像是这样的

00:01:57.290 --> 00:02:01.790
这个是什么 ? 它的值是多少 ?

00:02:01.790 --> 00:02:04.640
还有一个帮助函数

00:02:04.640 --> 00:02:07.745
可以让我们查看任何一个数字（0-9）的前 50个图像

00:02:07.745 --> 00:02:10.250
同样 你可以在下面的 notebook 中获取此函数

00:02:10.250 --> 00:02:12.379
所以利用这个函数 

00:02:12.379 --> 00:02:15.590
我们可以传入我们想要看到的数字 

00:02:15.590 --> 00:02:19.430
它们将允许我们查看这个数字的前 50个图像

00:02:19.430 --> 00:02:22.240
所以在这里 你可以看到前 50个

00:02:22.240 --> 00:02:26.775
这个是我们之前看到的数字 看看这一个

00:02:26.775 --> 00:02:28.969
其中一些看起来很容易

00:02:28.969 --> 00:02:31.074
用机器学习算法来预测

00:02:31.074 --> 00:02:34.219
但其他的肯定更难

00:02:34.219 --> 00:02:36.634
为了第一次预测这些

00:02:36.634 --> 00:02:38.989
我还编写了另一个帮助函数 

00:02:38.990 --> 00:02:41.920
它允许你将这些传递给一个随机林算法

00:02:41.919 --> 00:02:44.569
利用这个 random_forest_classifier 函数 

00:02:44.569 --> 00:02:46.090
它在下面的 notebook 中

00:02:46.090 --> 00:02:50.189
你可以看到它正在将数据集拆分为训练集和测试集

00:02:50.189 --> 00:02:53.859
实例化 RandomForestClassifier 

00:02:53.860 --> 00:02:57.735
将其在训练集上拟合 然后在测试集上进行预测

00:02:57.735 --> 00:03:01.295
然后生成一个包含以下结果的混淆矩阵

00:03:01.294 --> 00:03:03.219
让我们看看它做的好不好

00:03:03.219 --> 00:03:06.080
所以 对角线上的数字是

00:03:06.080 --> 00:03:09.705
预测值和实际标签值一样的个数 

00:03:09.705 --> 00:03:12.215
而非对角线上任何数字 

00:03:12.215 --> 00:03:15.205
都是我们预测错误的个数

00:03:15.205 --> 00:03:18.210
你可以看到 几乎 94% 的时间里

00:03:18.210 --> 00:03:22.795
我们可以使用这些图像中的全部像素来正确地预测

00:03:22.794 --> 00:03:26.269
这里 你可以看到深蓝色表示

00:03:26.270 --> 00:03:30.425
在非对角线区域的两边几乎没有被错误标记的图像

00:03:30.425 --> 00:03:33.740
这些沿着对角线的数字表明 

00:03:33.740 --> 00:03:37.830
确实有很多与此值相关的图像被正确预测

00:03:37.830 --> 00:03:41.650
所以我们可以看到 我们可以用这些像素进行很好的预测 

00:03:41.650 --> 00:03:45.670
但是我想知道我们是否可以使用PCA来创建更少的特征 

00:03:45.669 --> 00:03:50.464
并且仍然能够以相同的准确度进行预测

00:03:50.465 --> 00:03:55.375
为此 还有一个额外的帮助函数对数据集执行PCA

00:03:55.375 --> 00:04:01.150
因此 这个 do_pca 函数需要两个参数 特征数量和数据集 

00:04:01.150 --> 00:04:03.580
它拟合 PCA 

00:04:03.580 --> 00:04:06.680
然后通过 X 矩阵返回减少的特征 

00:04:06.680 --> 00:04:09.230
以及拟合好的PCA模型

00:04:09.229 --> 00:04:13.674
让我们尝试创建两个额外的特征

00:04:13.675 --> 00:04:18.280
所以我将传入两个特征以及这个 X 矩阵

00:04:18.279 --> 00:04:23.904
它是我们所有的像素 然后它会返回一个 PCA 对象

00:04:23.904 --> 00:04:30.284
所以我就称之为 pca 它还会给我一个与我们的 PCA 相关的 X 矩阵

00:04:30.285 --> 00:04:33.655
因此 使用这个 do_pca 函数 

00:04:33.654 --> 00:04:36.549
你可以看到它需要两个参数 成分数量

00:04:36.550 --> 00:04:39.375
以及输入数据（数据集的特征）

00:04:39.375 --> 00:04:43.550
然后它返回的是pca对象本身

00:04:43.550 --> 00:04:48.100
以及经过特征变换的数据帧对象

00:04:48.100 --> 00:04:53.490
所以 利用这个 我们可以得到拟合好的 pca

00:04:53.490 --> 00:04:59.280
和这个经过特征变换的X_pca 然后执行 PCA 

00:04:59.279 --> 00:05:04.839
假设我们需要返回两个成分 并在数据集的 X 矩阵上执行它

00:05:04.839 --> 00:05:07.304
所以 这是我们得到的数据帧 

00:05:07.305 --> 00:05:12.230
如果我们看X_pca的形状 它有相同的行数

00:05:12.230 --> 00:05:14.390
但你可以看到它只有两列 

00:05:14.389 --> 00:05:19.024
这与原始数据的行数相同 

00:05:19.024 --> 00:05:24.620
但每个图像的数据帧有 784个像素的列有很大不同

00:05:24.620 --> 00:05:31.670
所以让我们再次尝试使用在这里使用过的相同的机器学习算法

00:05:31.670 --> 00:05:33.160
随机森林分类器 

00:05:33.160 --> 00:05:37.895
我们可以看到我们如何能够预测只有两个特征的数字

00:05:37.894 --> 00:05:44.189
我们试试这个 所以 我们将使用的 X 矩阵是 X_pca 然后我们将预测y

00:05:44.189 --> 00:05:46.644
很酷 所以你可以看到

00:05:46.644 --> 00:05:51.279
它的性能比上一个例子差很多  

00:05:51.279 --> 00:05:58.309
我们只有35%的数字被正确分类  通过这个矩阵你可以看到这里

00:05:58.310 --> 00:06:01.240
真的 我们唯一预测得很好的就是这些数字 1 

00:06:01.240 --> 00:06:05.685
其他的都很糟糕 数字7也可以

00:06:05.685 --> 00:06:08.225
但我们并没有从中得到很多特征

00:06:08.225 --> 00:06:13.680
为了更好地理解这些成分是如何被从手写数字中分离出来的

00:06:13.680 --> 00:06:16.439
让我们使用这个 plot_components 函数

00:06:16.439 --> 00:06:20.725
所以 一个理想的情况是 如果我们把所有的值都画出来 

00:06:20.725 --> 00:06:23.275
我们的图会变得非常密集

00:06:23.274 --> 00:06:30.019
所以我要做的就是取前100个图像 
107
00:06:30,019 --&gt; 00:06:32,889
你可以看到  它在分离 0 

00:06:32.889 --> 00:06:34.949
和 7 个方面做得很好

00:06:34.949 --> 00:06:37.314
但其他的数字都是聚集在一起的 

00:06:37.314 --> 00:06:42.199
这正是我们在混淆矩阵中看到的东西

