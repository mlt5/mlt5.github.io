WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:03.720
GMM 聚类是一个很强大的方法

00:00:03.720 --> 00:00:07.679
它有很多优势

00:00:07.679 --> 00:00:10.184
其中之一就是为我们提供软聚类

00:00:10.185 --> 00:00:13.796
软聚类是多个聚类的示例性隶属度

00:00:13.795 --> 00:00:17.384
比如说 你正在对文档进行分类

00:00:17.385 --> 00:00:21.750
并且你希望每个文档都是多个主题

00:00:21.750 --> 00:00:25.125
或多个类别的一部分的情况下

00:00:25.125 --> 00:00:30.615
GMM 聚类对于这些场景很有用

00:00:30.614 --> 00:00:36.765
但除此之外 它在聚类外观方面也很具灵活性

00:00:36.765 --> 00:00:39.210
正如我们看过的例子中

00:00:39.210 --> 00:00:42.884
一个聚类中可以包含另一个聚类

00:00:42.884 --> 00:00:45.375
另一方面 GMM 聚类也有许多缺点

00:00:45.375 --> 00:00:49.725
GMM 聚类对初始化值很敏感

00:00:49.725 --> 00:00:55.020
它有可能收敛到局部最优 但收敛速度慢

00:00:55.020 --> 00:01:01.455
但是 这是一个非常有用而强大的聚类算法

00:01:01.454 --> 00:01:05.340
我们将在接下来的的几个应用中看到

00:01:05.340 --> 00:01:09.564
我们要看的第一个应用就是这篇非常酷的论文

00:01:09.564 --> 00:01:15.064
它特意使用了 GMM 聚类或者高斯混合模型

00:01:15.064 --> 00:01:18.920
来读懂大量的传感器读数

00:01:18.920 --> 00:01:24.469
它所使用的一个数据集就是加速度计读数

00:01:24.469 --> 00:01:29.750
假如你让人们在口袋中携带一个加速度计

00:01:29.750 --> 00:01:35.405
然后你得到读数并试图理解这些读数

00:01:35.405 --> 00:01:39.439
高斯混合模型在创建不同活动的外观方面

00:01:39.439 --> 00:01:43.370
非常有用

00:01:43.370 --> 00:01:46.829
因此 这是通勤的图像

00:01:46.829 --> 00:01:48.974
这是在办公室工作的图像

00:01:48.974 --> 00:01:52.679
这些都可以通过高斯混合来估量

00:01:52.680 --> 00:01:56.130
所以 你可以学习这些高斯混合 

00:01:56.129 --> 00:02:01.004
并基于加速度计读数来辨别不同的活动

00:02:01.004 --> 00:02:08.549
这篇文章中还有另一个基于 GPS 读数的速度数据集

00:02:08.550 --> 00:02:14.805
所以 利用那些 GPS 读数和高斯混合模型聚类

00:02:14.805 --> 00:02:20.270
通过估量 发现并学习这些活动的高斯混合模型外观

00:02:20.270 --> 00:02:22.045
你可以发现人们在什么时候骑自行车

00:02:22.044 --> 00:02:25.429
他们是在骑自行车

00:02:25.430 --> 00:02:29.569
还是乘公交或地铁

00:02:29.569 --> 00:02:32.329
所以这是速度 这是密度

00:02:32.330 --> 00:02:34.036
因此 当你骑自行车时

00:02:34.036 --> 00:02:40.310
大多数时候 你的速度都在 2m/s 或 3m/s

00:02:40.310 --> 00:02:42.875
就是这个高峰

00:02:42.875 --> 00:02:46.879
所以我强烈推荐学习这篇文章

00:02:46.879 --> 00:02:50.870
研究他们是如何应用 GMMs 

00:02:50.870 --> 00:02:59.039
利用高斯混合模型来分类天文学中的脉冲星也十分有效

00:02:59.039 --> 00:03:00.150
这是一种常见的用法

00:03:00.150 --> 00:03:01.987
你会发现许多相关文章

00:03:01.987 --> 00:03:03.615
这只是其中之一

00:03:03.615 --> 00:03:09.060
高斯混合模型也早就在生物识别中有所应用

00:03:09.060 --> 00:03:13.170
说话人确认 也是其中一例
48
00:03:13,169 --&gt; 00:03:17,099,
但它也用于识别人的签名

00:03:17.099 --> 00:03:20.835
指纹和其他类型的生物识别

00:03:20.835 --> 00:03:24.300
我想说 到目前为止

00:03:24.300 --> 00:03:26.820
高斯混合模型最酷的应用还是计算机视觉

00:03:26.819 --> 00:03:28.259
我们来看这个例子

00:03:28.259 --> 00:03:31.724
我们把这个图片提供给这个模型

00:03:31.724 --> 00:03:35.729
同时也把这个流式视频提供给模型

00:03:35.729 --> 00:03:39.000
它所做的就是检测背景

00:03:39.000 --> 00:03:42.419
并从最初的图像中移除它

00:03:42.419 --> 00:03:47.264
那么这样做实际上是给每个像素一个高斯混合模型

00:03:47.264 --> 00:03:51.839
然后用这个流式视频学习一个模型

00:03:51.840 --> 00:03:59.870
一个实际发生在多个帧的像素中的高斯混合

00:03:59.870 --> 00:04:03.849
然后使用它可以检测背景

00:04:03.849 --> 00:04:07.000
因此 我们可以基本上把它看作是大多数

00:04:07.000 --> 00:04:10.419
而不是全部元素

00:04:10.419 --> 00:04:12.894
但也许是大多数框架中常见的元素背景

00:04:12.895 --> 00:04:15.850
所以一旦我们确定了它 我们就可以确定前景是什么

00:04:15.849 --> 00:04:19.045
然后我们可以从这里移除它

00:04:19.045 --> 00:04:20.439
我们回到这里

00:04:20.439 --> 00:04:25.254
可以看到这里有一辆车 我们慢慢学习其模型

00:04:25.254 --> 00:04:27.189
然后我们就可以让它消失

00:04:27.189 --> 00:04:29.649
所以当我们确定背景和前景

00:04:29.649 --> 00:04:32.620
我们就可以做到这点

00:04:32.620 --> 00:04:34.375
这是一张不同的画面

00:04:34.375 --> 00:04:36.879
但对它所做的和前面基本相同

00:04:36.879 --> 00:04:41.050
这也是使用高斯混合模型来移除背景

00:04:41.050 --> 00:04:45.415
所以 一旦我们确定背景 我们就可以移除它

00:04:45.415 --> 00:04:50.590
剩下的就是前景中的物体

00:04:50.589 --> 00:04:52.539
我们可以利用这点进行人员追踪

00:04:52.540 --> 00:04:57.655
识别摄像头中正在移动的物体等

00:04:57.654 --> 00:05:03.069
这些和其他示例文件都链接在下面的文本中

