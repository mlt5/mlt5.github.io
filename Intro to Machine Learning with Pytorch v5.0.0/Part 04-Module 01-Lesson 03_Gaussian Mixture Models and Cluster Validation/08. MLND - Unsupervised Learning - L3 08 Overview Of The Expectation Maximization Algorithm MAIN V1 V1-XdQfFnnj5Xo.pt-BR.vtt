WEBVTT
Kind: captions
Language: pt-BR

00:00:00.347 --> 00:00:02.230
Aqui, temos
um panorama geral

00:00:02.260 --> 00:00:05.381
de como o Agrupamento Modelo
de Mistura de gaussianas funciona,

00:00:05.411 --> 00:00:08.462
e vamos usar o conjunto de dados
do qual falamos no vídeo anterior

00:00:08.492 --> 00:00:09.773
para fazer isso.

00:00:09.803 --> 00:00:12.214
Para fazer esse agrupamento,
precisamos seguir

00:00:12.244 --> 00:00:15.077
o algoritmo de maximização
da expectativa

00:00:15.107 --> 00:00:16.877
para mistura de gaussianas.

00:00:16.907 --> 00:00:18.765
E isso funciona assim:

00:00:18.795 --> 00:00:23.061
o primeiro passo é inicializar
"K" distribuições de Gauss.

00:00:23.091 --> 00:00:25.636
K, neste caso,
neste exemplo, é 2,

00:00:25.666 --> 00:00:28.220
porque sabemos que havia
dois conjuntos de dados originais,

00:00:28.250 --> 00:00:29.604
duas fontes originais.

00:00:29.638 --> 00:00:32.719
O segundo passo é fazer
o agrupamento suave dos dados

00:00:32.753 --> 00:00:35.934
nas duas gaussianas
que inicializamos.

00:00:35.964 --> 00:00:39.438
Este é o chamado "passo
de expectativa", ou "passo E".

00:00:39.468 --> 00:00:43.012
O terceiro passo é reestimar
as gaussianas

00:00:43.042 --> 00:00:45.453
baseado no agrupamento
suave.

00:00:45.483 --> 00:00:47.581
Este é o chamado "passo
de maximização",

00:00:47.611 --> 00:00:48.972
ou "passo M".

00:00:49.002 --> 00:00:52.493
No quarto passo, avaliamos
a log-verossimilhança

00:00:52.523 --> 00:00:54.709
para verificar convergências.

00:00:54.739 --> 00:00:59.133
Se ele convergir, está tudo certo
e retornamos os valores.

00:00:59.163 --> 00:01:03.293
Se não, voltamos ao passo 2,
reiteramos

00:01:03.323 --> 00:01:04.789
e fazemos tudo de novo

00:01:04.819 --> 00:01:09.118
até convergirmos e encontrarmos
as duas gaussianas que queremos.

00:01:09.762 --> 00:01:12.022
Este é um rápido panorama
do algoritmo.

00:01:12.379 --> 00:01:15.214
Vamos vê-lo mais detalhadamente
no próximo vídeo.

