WEBVTT
Kind: captions
Language: zh-CN

00:00:00.250 --> 00:00:03.919
此前 XOR 感知器例子显示 通过加深层数

00:00:03.919 --> 00:00:08.289
模型得以解决非线性问题

00:00:08.289 --> 00:00:13.079
这是一个多层感知器的示例 内含 3 个输入单元

00:00:13.080 --> 00:00:16.530
1 个输出单元 与 2 个中间层单元

00:00:16.530 --> 00:00:19.089
这个中间层又称隐藏层

00:00:19.089 --> 00:00:22.960
神经网络整体计算方法并未变化 只是现在

00:00:22.960 --> 00:00:27.589
隐藏层的激活值被用作输出层的输入值

00:00:27.589 --> 00:00:30.370
隐藏层的输入计算方法仍与之前相同

00:00:30.370 --> 00:00:34.469
等于权重值乘以输入值 加上偏置项

00:00:34.469 --> 00:00:39.329
而且和之前一样 需要使用 sigmoid 等激活函数

00:00:39.329 --> 00:00:41.979
来计算隐藏层的输出值

00:00:41.979 --> 00:00:44.619
隐藏层的激活值通过乘以第二组权重

00:00:44.619 --> 00:00:46.329
传递到输出层

00:00:46.329 --> 00:00:49.799
并再次使用激活函数求得最终输出值

00:00:49.799 --> 00:00:50.539
通过更深层次的堆叠

00:00:50.539 --> 00:00:54.570
神经网络能够学习更加复杂的模式

00:00:54.570 --> 00:00:57.500
这就是深度学习的名称由来 

00:00:57.500 --> 00:00:58.479
其强大之处

00:00:58.479 --> 00:01:00.009
也源于隐藏层的深度堆叠

