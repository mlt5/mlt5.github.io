WEBVTT
Kind: captions
Language: en

00:00:03.799 --> 00:00:07.214
You've already seen in supervised learning,

00:00:07.214 --> 00:00:10.244
that it's imperative for you to scale your variables.

00:00:10.244 --> 00:00:13.199
K-means is another algorithm that uses

00:00:13.199 --> 00:00:17.339
distances to determine which group a point belongs to.

00:00:17.339 --> 00:00:21.184
So feature scaling is absolutely necessary for this algorithm.

00:00:21.184 --> 00:00:24.279
There are number of scalings you might choose to do.

00:00:24.280 --> 00:00:30.130
From standardizing, or Z-score scaling to normalizing, or min-max scaling.

00:00:30.129 --> 00:00:33.060
We usually use standardizing with clustering

00:00:33.060 --> 00:00:36.950
algorithms as well as with transformations like PCA and ICA,

00:00:36.950 --> 00:00:39.130
which you'll see later on in this course.

00:00:39.130 --> 00:00:44.844
Alternatively, we use normalizing when scaling the coloring of an image.

00:00:44.844 --> 00:00:47.199
If you do not scale your features,

00:00:47.200 --> 00:00:52.234
the features with much larger variance will dominate the importance in clustering.

00:00:52.234 --> 00:00:55.104
Even if it's just because of the choice of units,

00:00:55.104 --> 00:00:57.909
you do not want this to happen.

