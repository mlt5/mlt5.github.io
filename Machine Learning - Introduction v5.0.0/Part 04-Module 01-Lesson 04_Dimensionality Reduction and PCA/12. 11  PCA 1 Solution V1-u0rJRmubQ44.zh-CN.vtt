WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:01.360
在上一个视频中

00:00:01.360 --> 00:00:05.425
你看到了使用 MNIST 数据集中的数字的示例

00:00:05.424 --> 00:00:07.915
可以在这里找到该数据集的链接

00:00:07.915 --> 00:00:11.155
首先 我们先要加载一些要用到的库

00:00:11.154 --> 00:00:13.750
然后 我们将解决一些问题

00:00:13.750 --> 00:00:16.440
首先要注意的是 有很多东西

00:00:16.440 --> 00:00:19.185
是从这个 helper 函数库加载的

00:00:19.184 --> 00:00:24.210
这些基本上是你在上一个视频中看到的一些函数 

00:00:24.210 --> 00:00:25.740
以及一些其他东西

00:00:25.739 --> 00:00:27.629
我们将在整个 notebook 中看到

00:00:27.629 --> 00:00:31.554
所以 我们需要做的第一件事是使用 pandas 读取数据集 

00:00:31.554 --> 00:00:34.335
你可以在这个链接中看到它

00:00:34.335 --> 00:00:38.310
你也可以通过输入 head 、tail、

00:00:38.310 --> 00:00:43.145
describe、info 等命令来查看数据 看看它看起来是什么样子 并确保你感到合适

00:00:43.145 --> 00:00:46.520
与上一个视频类似 我们创建一个名为 y 的向量来保存标签值

00:00:46.520 --> 00:00:49.680
并将所有剩余像素值存储在 x 中

00:00:49.679 --> 00:00:57.484
我还将使用零填充 就像我们在上一个视频中看到的 很好

00:00:57.484 --> 00:00:59.564
所以 看起来一切正常

00:00:59.564 --> 00:01:05.250
现在 使用 helper 函数中的 show_images_by_digit 函数来查看

00:01:05.250 --> 00:01:08.170
1、2、3 或任何其他值

00:01:08.170 --> 00:01:12.034
通过运行此命令 我们将看到数据集中的所有的数字 2 的图像 

00:01:12.034 --> 00:01:15.155
如果我们改变这个 我们可以看看数字 1 

00:01:15.155 --> 00:01:19.030
我们也可以看看数字 8

00:01:19.030 --> 00:01:21.780
现在我们有机会查看这些数据

00:01:21.780 --> 00:01:24.320
让我们尝试使用这个四个步骤来拟合模型

00:01:24.319 --> 00:01:28.284
并通过预测数字来对模型评分

00:01:28.284 --> 00:01:31.109
所以 上一个视频中使用的模型 

00:01:31.109 --> 00:01:33.015
就是通过这个函数来实现的

00:01:33.015 --> 00:01:35.019
这个 fit_random_forest_classifier 

00:01:35.019 --> 00:01:38.954
但你也可以尝试做网格搜索 来找到比这个更好的模型

00:01:38.954 --> 00:01:41.299
我们需要做一个 in-place=True 操作(即在原对象上修改) 

00:01:41.299 --> 00:01:44.084
以确保数据集的缺失值被填充为 0

00:01:44.084 --> 00:01:49.774
然后 在这里你可以看到关于我们的模型表现如何的一个例子  

00:01:49.775 --> 00:01:53.680
同样 还是你在上一段视频中看到的 94% 的分数

00:01:53.680 --> 00:01:58.380
所以 整个这节课的目的是看 PCA

00:01:58.379 --> 00:02:01.879
要复制在上一个视频中看到的过程 

00:02:01.879 --> 00:02:05.334
可以使用已经创建好的 do_pca 函数

00:02:05.334 --> 00:02:08.699
如果我们运行它 你可以看到它接受两个输入参数 

00:02:08.699 --> 00:02:11.060
目标特征的数量 

00:02:11.060 --> 00:02:14.224
和原始特征数据集

00:02:14.224 --> 00:02:17.569
然后输出的是 pca 模型

00:02:17.569 --> 00:02:21.275
以及经过降维的较少的特征的数据集

00:02:21.275 --> 00:02:23.870
给它输入目标特征的数量

00:02:23.870 --> 00:02:27.230
我在前面的视频中只使用了两个特征创建了一个模型 

00:02:27.229 --> 00:02:30.090
但是如果你愿意的话 可以尝试使用更多的特征

00:02:30.090 --> 00:02:34.969
我们将传入 x 矩阵 然后输出的两个东西是

00:02:34.969 --> 00:02:40.359
这个 pca 对象和经过降维的 x 矩阵

00:02:40.360 --> 00:02:46.280
现在 我们已经得到返回的 pca 对象和仅包含两个特征的缩减的特征集

00:02:46.280 --> 00:02:47.965
下一步我们可以做的是

00:02:47.965 --> 00:02:50.205
拟合一个随机森林分类器

00:02:50.205 --> 00:02:53.850
这是上一个视频中创建的函数之一 

00:02:53.849 --> 00:02:56.299
你可以看到它的输入包含了 x 和 y 

00:02:56.300 --> 00:02:58.880
它打印了这个混淆矩阵和精确度

00:02:58.879 --> 00:03:02.560
所以 在这种情况下 你可以看到它的表现不是很好 

00:03:02.560 --> 00:03:06.319
至少与使用所有特征的模型不可比

00:03:06.319 --> 00:03:09.319
在下一部分中 我们想看看是否可以找到特征数量减少

00:03:09.319 --> 00:03:13.314
但准确度仍能超过 90% 的特征集

00:03:13.314 --> 00:03:18.094
所以 让我们遍历每个特征

00:03:18.094 --> 00:03:22.544
让我们先从 哦 我们知道不能

00:03:22.544 --> 00:03:27.234
所以 也许是3 也许我们会到15

00:03:27.235 --> 00:03:29.425
抱歉 我跳过了第七个问题

00:03:29.425 --> 00:03:31.370
所以 接下来我们可以做的是

00:03:31.370 --> 00:03:34.460
使用你在视频中看到的 利用这个 plot_components 函数 

00:03:34.460 --> 00:03:36.125
看看分离的效果如何

00:03:36.125 --> 00:03:38.210
所以 这正是我们以前看到的

00:03:38.210 --> 00:03:40.224
现在 让我们再往前走一点

00:03:40.224 --> 00:03:43.745
在这种情况下 我们想看看是否能得到更好的分离

00:03:43.745 --> 00:03:47.360
具体来说 我们希望减少特征数量（使其少于全部 700 多个特征）

00:03:47.360 --> 00:03:51.900
但仍希望获得超过 90% 的准确度

00:03:51.900 --> 00:03:55.110
我们先从 3 到 15 的范围开始 

00:03:55.110 --> 00:03:57.790
如果需要的话 我们可以以后再提高

00:03:57.789 --> 00:04:03.074
所以 我要把它传给执行 PCA 的部分

00:04:03.074 --> 00:04:06.454
执行 PCA 实际上是这里的一个函数

00:04:06.455 --> 00:04:09.020
所以 好的部分是 

00:04:09.020 --> 00:04:12.230
它不仅打印出准确度 而且还将准确度返回

00:04:12.229 --> 00:04:15.364
我们可以这么说 因为它就在外面这里

00:04:15.365 --> 00:04:19.240
因此 对于 3 到 15 之间的每个特征数 

00:04:19.240 --> 00:04:23.555
我们要做的是运行这个 do_pca 算法 该算法将返回 PCA 对象

00:04:23.555 --> 00:04:28.925
和经过降维的 x 矩阵

00:04:28.925 --> 00:04:34.295
然后我们要做的是运行这个随机森林分类器 就是这一部分

00:04:34.295 --> 00:04:37.560
随机森林分类器接受两个参数 x 和 y

00:04:37.560 --> 00:04:40.375
所以 X_pca 和 y

00:04:40.375 --> 00:04:44.589
它们实际上返回了准确度

00:04:44.589 --> 00:04:47.524
我们之所以知道它返回准确度 

00:04:47.524 --> 00:04:51.054
是因为这部分在这里是返回出来的

00:04:51.055 --> 00:04:56.209
我要做的是创建一个名为 ACCS 的空列表

00:04:56.209 --> 00:05:03.944
然后我要做的是把这些模型的准确度添加到列表中

00:05:03.944 --> 00:05:13.099
然后我还将在循环之外创建一个名称为 num_features 的列表 很好

00:05:13.100 --> 00:05:15.340
所以 这会生成出一大堆这些

00:05:15.339 --> 00:05:18.379
所以 这是三个特征情况下的结果

00:05:18.379 --> 00:05:21.384
你可以看到我们得到了约54%的准确度

00:05:21.384 --> 00:05:25.925
然后 在四个特征情况下 我们得到了约 67% 的准确度

00:05:25.925 --> 00:05:30.235
然后 在五个特征情况下 我们得到了约 72% 的准确度

00:05:30.235 --> 00:05:36.030
然后 六个特征情况下 我们得到了约 80% 的准确度

00:05:36.029 --> 00:05:38.304
你可以看到我们开始变平缓了

00:05:38.305 --> 00:05:40.879
然后 我们得到 84、85

00:05:40.879 --> 00:05:44.310
86 看起来已经跑完了

00:05:44.310 --> 00:05:49.129
因此 在有14个特征情况下 我们几乎达到了 88%

00:05:49.129 --> 00:05:53.120
看来我们得再高一点

00:05:53.120 --> 00:06:02.160
所以 我要做的是从15开始 直到 也许可以说 20个特征 好吧

00:06:02.160 --> 00:06:07.335
所以 使用15个特征 我们就有了 90 非常接近

00:06:07.334 --> 00:06:10.404
但更明智的方法是构造一个中断语句

00:06:10.404 --> 00:06:14.959
当模型的准确度到达阈值后我们就中断

00:06:14.959 --> 00:06:19.439
所以 如果我们存储了这个准确度 然后再在后面添加它

00:06:19.439 --> 00:06:24.875
我们说 acc 等于这个

00:06:24.875 --> 00:06:32.685
然后添加这个准确度 如果 acc 大于 0.9 就中断循环

00:06:32.685 --> 00:06:35.360
这可能是最聪明的方法 

00:06:35.360 --> 00:06:37.905
然后从15运行到 好吧

00:06:37.904 --> 00:06:40.209
我是说现在我们可以做到100

00:06:40.209 --> 00:06:42.669
但从20开始可能更聪明

00:06:42.670 --> 00:06:45.080
这一部分在这里没有任何意义

00:06:45.079 --> 00:06:49.539
所以 在20的时候 我们的准确度是90

00:06:49.540 --> 00:06:52.435
它正在下降 好了

00:06:52.435 --> 00:06:58.459
现在 如果我们在下面插入一个单元格 就可以打印

00:06:58.459 --> 00:07:01.649
我们可以只看 accs

00:07:01.649 --> 00:07:03.114
一共有 11个

00:07:03.115 --> 00:07:05.975
所以 你可以看到我们做了 11个 是的

00:07:05.975 --> 00:07:07.500
从 20 到 30

00:07:07.500 --> 00:07:12.379
所以 基本上 一旦我们有了 30个特征 

00:07:12.379 --> 00:07:17.795
这些特征足以很好地理解数字 预测的准确度可以比 90% 的更好

00:07:17.795 --> 00:07:23.395
我们以前有 700多个特征 这真是一个非常大的减少

00:07:23.394 --> 00:07:27.894
额外的特征实际上可能会导致过拟合

00:07:27.894 --> 00:07:31.789
然后 这个问题问你是否有证据证明这个数据集发生了这种情况

00:07:31.790 --> 00:07:35.314
在解决方案文件中 你可以在此 notebook 中找到

00:07:35.314 --> 00:07:39.769
它从一个相当大的范围来看 

00:07:39.769 --> 00:07:42.964
建议只看 100个以下的特征

00:07:42.964 --> 00:07:47.204
所以 我们可以做的基本上是运行100个特征

00:07:47.204 --> 00:07:52.284
然后 在多个特征上绘制准确度图 看看是否开始下降

00:07:52.285 --> 00:07:54.055
或 CFR 拟合的好不好

00:07:54.055 --> 00:07:57.000
但从本质上看 和这里的过程是一样的

