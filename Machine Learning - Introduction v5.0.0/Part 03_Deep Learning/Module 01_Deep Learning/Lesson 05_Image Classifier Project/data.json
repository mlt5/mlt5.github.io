{
  "data": {
    "lesson": {
      "id": 842129,
      "key": "567be3c5-da69-4c49-9d56-a0048d299b89",
      "title": "Image Classifier Project",
      "semantic_type": "Lesson",
      "is_public": true,
      "version": "1.0.0",
      "locale": "en-us",
      "summary": "In this project, you'll build a Python application that can train an image classifier on a dataset, then predict new images using the trained model.",
      "lesson_type": "Classroom",
      "display_workspace_project_only": false,
      "resources": {
        "files": [
          {
            "name": "Videos Zip File",
            "uri": "https://zips.udacity-data.com/567be3c5-da69-4c49-9d56-a0048d299b89/842129/1554416148887/Image+Classifier+Project+Videos.zip"
          },
          {
            "name": "Transcripts Zip File",
            "uri": "https://zips.udacity-data.com/567be3c5-da69-4c49-9d56-a0048d299b89/842129/1554416146971/Image+Classifier+Project+Subtitles.zip"
          }
        ],
        "google_plus_link": null,
        "career_resource_center_link": null,
        "coaching_appointments_link": null,
        "office_hours_link": null,
        "aws_provisioning_link": null
      },
      "project": {
        "key": "82955e22-254c-47fa-aa89-e7c8bdcdedcb",
        "version": "1.0.0",
        "locale": "en-us",
        "duration": 33120,
        "semantic_type": "Project",
        "title": "Create Your Own Image Classifier",
        "description": "# Project submission\n\nFor a successful project submission, you'll need to include these files in a ZIP archive:\n\n* The completed Jupyter Notebook from Part 1 as an HTML file and any extra files you created that are necessary to run the code in the notebook\n* The `train.py` and `predict.py` files from Part 2, as well as any other files necessary to run those scripts\n\nYou can download these files individually from the workspaces.\n\n**NOTE:** Do not include the data in the submission archive.\n\n## Project Submission Checklist\n\n**Before submitting your project, please review and confirm the following items.** \n<input type=\"checkbox\"> I am confident all rubric items have been met and my project will pass as submitted. \n<input type=\"checkbox\"> Project builds correctly without errors and runs.\n<input type=\"checkbox\"> All required functionality exists and my project behaves as expected per the project's specifications.\n\n**Once you have checked all these items, you are ready to submit!**\n",
        "is_public": true,
        "summary": null,
        "forum_path": "",
        "rubric_id": "2537",
        "terminal_project_id": null,
        "resources": null,
        "image": null
      },
      "lab": null,
      "concepts": [
        {
          "id": 534662,
          "key": "84d42c50-f836-479c-9f42-b26eb14e409f",
          "title": "Project Intro",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "84d42c50-f836-479c-9f42-b26eb14e409f",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 534666,
              "key": "8a7e0f8d-73a2-48f7-a341-b908799af8de",
              "title": "PROJECT INTRO MAIN V2",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "--9IFCNBM6Y",
                "china_cdn_id": "--9IFCNBM6Y.mp4"
              }
            }
          ]
        },
        {
          "id": 498491,
          "key": "8b7e602a-4a29-4009-b162-73c6051d4647",
          "title": "Introduction to GPU Workspaces",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "8b7e602a-4a29-4009-b162-73c6051d4647",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": {
            "files": [
              {
                "name": "workspace_utils.py",
                "uri": "https://video.udacity-data.com/topher/2018/May/5b06f6c2_workspace-utils/workspace-utils.py"
              }
            ],
            "google_plus_link": null,
            "career_resource_center_link": null,
            "coaching_appointments_link": null,
            "office_hours_link": null,
            "aws_provisioning_link": null
          },
          "atoms": [
            {
              "id": 498550,
              "key": "43033f6d-6756-4208-9782-c3a7a4cd3de0",
              "title": null,
              "semantic_type": "ImageAtom",
              "is_public": true,
              "url": "https://video.udacity-data.com/topher/2018/January/5a501791_jupyter-logo/jupyter-logo.png",
              "non_google_url": "https://s3.cn-north-1.amazonaws.com.cn/u-img/43033f6d-6756-4208-9782-c3a7a4cd3de0",
              "caption": "",
              "alt": "",
              "width": 208,
              "height": 56,
              "instructor_notes": null
            },
            {
              "id": 498551,
              "key": "3f8a5696-c478-4920-90e1-81b795aa1d28",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "## Introduction\n---\n\nUdacity Workspaces with GPU support are available for some projects as an alternative to manually configuring your own remote server with GPU support. These workspaces provide a Jupyter notebook server directly in your browser. This lesson will briefly introduce the Workspaces interface.\n\n### Important Notes:\n\n- Workspaces sessions are connections from your browser to a remote server. Each student has a limited number of GPU hours allocated on the servers (the allocation is significantly more than completing the projects is expected to take). There is currently no limit on the number of Workspace hours when GPU mode is disabled.\n- Workspace data stored in the user's home folder is preserved between sessions (and can be reset as needed, e.g., to get project updates).\n- **Only 3 gigabytes of data can be stored in the home folder.**\n- Workspace sessions are preserved if your connection drops or your browser window is closed, simply return to the classroom and re-open the workspace page; however, workspace sessions are automatically terminated after a period of inactivity. This will prevent you from leaving a session connection open and burning through your time allocation. (See the section on active connections below.)\n- The kernel state is preserved as long as the notebook session remains open, but it is _not_ preserved if the session is closed. If you exit the notebook for more than half an hour and the session is closed, you will need to re-run any previously-run cells before continuing.\n\n## Overview\n---",
              "instructor_notes": ""
            },
            {
              "id": 498555,
              "key": "4c0b682a-fe2b-4924-8291-66a40fd6b46a",
              "title": null,
              "semantic_type": "ImageAtom",
              "is_public": true,
              "url": "https://video.udacity-data.com/topher/2018/January/5a501a04_workspaces-jupyter/workspaces-jupyter.png",
              "non_google_url": "https://s3.cn-north-1.amazonaws.com.cn/u-img/4c0b682a-fe2b-4924-8291-66a40fd6b46a",
              "caption": "The default workspaces interface",
              "alt": "Workspaces interface",
              "width": 1227,
              "height": 589,
              "instructor_notes": null
            },
            {
              "id": 498556,
              "key": "672eb443-24f0-4f36-b99d-8b9415e18745",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "When the workspace opens, you'll see the normal Jupyter file browser. From this interface you can open a notebook file, start a remote terminal session, enable the GPU, submit your project, or reset the workspace data, and more. Clicking the three bars in the top left corner above the Jupyter logo will toggle hiding the classroom lessons sidebar.\n\n**NOTE: You can always return to the file browser page from anywhere else in the workspace by clicking the Jupyter logo in the top left corner.**\n\n## Opening a notebook\n---",
              "instructor_notes": ""
            },
            {
              "id": 498557,
              "key": "cb33298c-6c37-43ec-9861-7de904dff2d6",
              "title": null,
              "semantic_type": "ImageAtom",
              "is_public": true,
              "url": "https://video.udacity-data.com/topher/2018/January/5a501a8d_workspaces-notebook/workspaces-notebook.png",
              "non_google_url": "https://s3.cn-north-1.amazonaws.com.cn/u-img/cb33298c-6c37-43ec-9861-7de904dff2d6",
              "caption": "View of the project notebook",
              "alt": "Project notebook view",
              "width": 1224,
              "height": 588,
              "instructor_notes": null
            },
            {
              "id": 498558,
              "key": "4aa8e179-7831-4a37-959c-dc26e66140d2",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "Clicking the name of a notebook (*.ipynb) file in the file list will open a standard Jupyter notebook view of the project. The notebook session will remain open as long as you are active, and will be automatically terminated after 30 minutes of inactivity. \n\nYou can exit a notebook by clicking on the Jupyter logo in the top left corner.\n\n**NOTE: Notebooks continue to run in the background unless they are stopped. IF GPU MODE IS ACTIVE, IT WILL REMAIN ACTIVE AFTER CLOSING OR STOPPING A NOTEBOOK. YOU CAN ONLY STOP GPU MODE WITH THE GPU TOGGLE BUTTON. (See next section.)**\n\n## Enabling GPU Mode\n---",
              "instructor_notes": ""
            },
            {
              "id": 498559,
              "key": "0e16c570-a956-4fb3-8d74-87a9977c7579",
              "title": null,
              "semantic_type": "ImageAtom",
              "is_public": true,
              "url": "https://video.udacity-data.com/topher/2018/January/5a501cb6_workspaces-gpu/workspaces-gpu.png",
              "non_google_url": "https://s3.cn-north-1.amazonaws.com.cn/u-img/0e16c570-a956-4fb3-8d74-87a9977c7579",
              "caption": "The GPU Toggle Button",
              "alt": "Enabling GPU mode",
              "width": 1224,
              "height": 588,
              "instructor_notes": null
            },
            {
              "id": 498560,
              "key": "31587370-cb43-4a3d-b010-336044267f32",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "GPU Workspaces can also be run without time restrictions when the GPU mode is disabled. The \"Enable\"/\"Disable\" button (circled in red in the image) can be used to toggle GPU mode. **NOTE: Toggling GPU support may switch the physical server your session connects to, which can cause data loss UNLESS YOU CLICK THE SAVE BUTTON BEFORE TOGGLING GPU SUPPORT.**\n\n**NOTE THAT THIS WORKSPACE CANNOT BE RUN WITHOUT THE GPU SUPPORT.**\n\n**ALWAYS SAVE YOUR CHANGES BEFORE TOGGLING GPU SUPPORT.**\n\n## Keeping Your Session Active\n---\nWorkspaces automatically disconnect after 30 minutes of user inactivity—which means that workspaces can disconnect during long-running tasks (like training neural networks). We have provided a utility that can keep your workspace sessions active for these tasks. However, keep the following guidelines in mind:\n\n- Do not try to permanently hold the workspace session active when you do not have a process running (e.g., do not try to hold the session open in the background)—the limits are in place to preserve your GPU time allocation; there is no guarantee that you'll receive additional time if you exceed the limit.  \n- Make sure that you save the results of the long running task to disk as soon as the task ends (e.g., checkpoint your model parameters for deep learning networks); otherwise the workspace will disconnect 30 minutes after the active process ends, and the results will be lost.\n\nThe `workspace_utils.py` module (available [here](https://s3.amazonaws.com/video.udacity-data.com/topher/2018/May/5b06f6c2_workspace-utils/workspace-utils.py)) includes an iterator wrapper called `keep_awake` and a context manager called `active_session` that can be used to maintain an active session during long-running processes. The two functions are equivalent, so use whichever fits better in your code.  **NOTE:** The file may be incorrectly downloaded as `workspace-utils.py` (note the dash instead of an underscore in the filename). Make sure to correct the filename before uploading to your workspace; Python cannot import from file names including hyphens.\n\nExample using `keep_awake`:\n```\nfrom workspace_utils import keep_awake\n\nfor i in keep_awake(range(5)):  #anything that happens inside this loop will keep the workspace active\n    # do iteration with lots of work here\n```\n\nExample using `active_session`:\n```\nfrom workspace_utils import active_session\n\nwith active_session():\n    # do long-running work here\n```\n\n## Submitting a Project\n---",
              "instructor_notes": ""
            },
            {
              "id": 498561,
              "key": "045515f3-a319-441f-86a9-cd4862f6e751",
              "title": null,
              "semantic_type": "ImageAtom",
              "is_public": true,
              "url": "https://video.udacity-data.com/topher/2018/January/5a501db1_workspaces-submit/workspaces-submit.png",
              "non_google_url": "https://s3.cn-north-1.amazonaws.com.cn/u-img/045515f3-a319-441f-86a9-cd4862f6e751",
              "caption": "The Submit Project Button",
              "alt": "UI annotation for project submission button",
              "width": 1224,
              "height": 588,
              "instructor_notes": null
            },
            {
              "id": 498564,
              "key": "d8cdd4ca-398e-485a-b958-a80c96233d92",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "Some workspaces are able to directly submit projects on your behalf (i.e., you do **not** need to manually submit the project in the classroom). To submit your project, simply click the \"Submit Project\" button (circled in red in the above image). \n\nIf you do not see the \"Submit Project\" button, then project submission is not enabled for that workspace. You will need to manually download your project files and submit them in the classroom.\n\n**NOTE: YOU MUST ENSURE THAT YOUR SUBMISSION INCLUDES ALL REQUIRED FILES BEFORE SUBMITTING -- INCLUDING ANY FILE CONVERSIONS (e.g., from ipynb to HTML)**\n\n## Opening a Terminal\n---",
              "instructor_notes": ""
            },
            {
              "id": 498568,
              "key": "f529706f-70c5-4ac8-834e-ab69c8a696d0",
              "title": null,
              "semantic_type": "ImageAtom",
              "is_public": true,
              "url": "https://video.udacity-data.com/topher/2018/January/5a501f0b_workspaces-new/workspaces-new.png",
              "non_google_url": "https://s3.cn-north-1.amazonaws.com.cn/u-img/f529706f-70c5-4ac8-834e-ab69c8a696d0",
              "caption": "The \"New\" menu button",
              "alt": "The \"new\" menu",
              "width": 1224,
              "height": 589,
              "instructor_notes": null
            },
            {
              "id": 498570,
              "key": "81021215-6310-437f-a0f2-2ca64969c112",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "Jupyter workspaces support several views, including the file browser and notebook view already covered, as well as shell terminals. To open a terminal shell, click the \"New\" menu button at the top right of the file browser view and select \"Terminal\".\n\n## Terminals\n---",
              "instructor_notes": ""
            },
            {
              "id": 498571,
              "key": "0f10c752-1676-4c98-af4f-cb5118a950d6",
              "title": null,
              "semantic_type": "ImageAtom",
              "is_public": true,
              "url": "https://video.udacity-data.com/topher/2018/January/5a50201e_workspaces-terminal/workspaces-terminal.png",
              "non_google_url": "https://s3.cn-north-1.amazonaws.com.cn/u-img/0f10c752-1676-4c98-af4f-cb5118a950d6",
              "caption": "Jupyter terminal shell interface",
              "alt": "Jupter terminal shell interface",
              "width": 1223,
              "height": 586,
              "instructor_notes": null
            },
            {
              "id": 498572,
              "key": "f9b26824-e4ae-4f4e-94ef-9f42d628e771",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "Terminals provide a full Bash shell that you can use to install or update software packages, fetch updates from github repositories, or run any other terminal commands. As with the notebook view, you can return to the file browser view by clicking on the Jupyter logo at the top left corner of the window.\n\n**NOTE: Your data & changes are persistent across workspace sessions. Any changes you make will need to be repeated if you later reset your workspace data.**\n\n## Resetting Data\n---",
              "instructor_notes": ""
            },
            {
              "id": 498573,
              "key": "95b31bc6-091a-4d39-b572-40c7e8e37c56",
              "title": null,
              "semantic_type": "ImageAtom",
              "is_public": true,
              "url": "https://video.udacity-data.com/topher/2018/January/5a502126_workspaces-menu/workspaces-menu.png",
              "non_google_url": "https://s3.cn-north-1.amazonaws.com.cn/u-img/95b31bc6-091a-4d39-b572-40c7e8e37c56",
              "caption": "The Menu Button",
              "alt": "Workspaces Menu Button",
              "width": 1224,
              "height": 589,
              "instructor_notes": null
            },
            {
              "id": 498574,
              "key": "26ea5715-b920-4d32-8b7c-9326c55512a8",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "The \"Menu\" button in the bottom left corner provides support for resetting your Workspaces. The \"Refresh Workspace\" button will refresh your session, which has no effect on the changes you've made in the workspace.\n\nThe \"Reset Data\" button discards all changes and restores a clean copy of the workspace. Clicking the button will open a dialog that requires you to type \"Reset data\" in a confirmation dialog. **ALL OF YOUR DATA WILL BE LOST.**\n\nResetting should only be required if Udacity makes changes to the project and you can't get them via `git pull`, or if you destroy the contents of the workspace. If you do need to reset your data, you are _strongly_ encouraged to download a copy of your work from the file interface before clicking Reset Data.",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 502599,
          "key": "a0638042-7d4c-4e3e-9d19-c71e6a87fe18",
          "title": "Image Classifier - Part 1 - Development",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "a0638042-7d4c-4e3e-9d19-c71e6a87fe18",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 531126,
              "key": "43fe9fcc-985c-44ee-8387-7053719cab08",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "# Developing an Image Classifier with Deep Learning\n\nIn this first part of the project, you'll work through a Jupyter notebook to implement an image classifier with PyTorch. We'll provide some tips and guide you, but for the most part the code is left up to you. As you work through this project, please [refer to the rubric](https://review.udacity.com/#!/rubrics/1663/view) for guidance towards a successful submission.\n\nRemember that your code should be your own, please do not plagiarize ([see here](https://udacity.zendesk.com/hc/en-us/articles/360001451091-What-is-plagiarism-) for more information).\n\nThis notebook will be required as part of the project submission. After you finish it, make sure you download it as an HTML file and include it with the files you write in the next part of the project.\n\nWe've provided you a workspace with a GPU for working on this project. If you'd instead prefer to work on your local machine, you can find the files [on GitHub here](https://github.com/udacity/aipnd-project).\n\nIf you are using the workspace, be aware that saving large files can create issues with backing up your work. You'll be saving a model checkpoint in Part 1 of this project which can be multiple GBs in size if you use a large classifier network. Dense networks can get large very fast since you are creating N x M weight matrices for each new layer. In general, it's better to avoid wide layers and instead use more hidden layers, this will save a lot of space. Keep an eye on the size of the checkpoint you create. You can open a terminal and enter `ls -lh` to see the sizes of the files. If your checkpoint is greater than 1 GB, reduce the size of your classifier network and re-save the checkpoint.\n",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 613881,
          "key": "313e2076-4626-4650-906a-ec82eb61c00e",
          "title": "Image Classifier - Part 1 - Workspace",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "313e2076-4626-4650-906a-ec82eb61c00e",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 613882,
              "key": "a6355b90-2c1f-4ddc-b5cb-a08992eb3884",
              "title": null,
              "semantic_type": "WorkspaceAtom",
              "is_public": true,
              "workspace_id": "view87cc5390",
              "pool_id": "jupytergpu",
              "view_id": "70831337-3d66-437d-947f-69b0181368ac",
              "gpu_capable": true,
              "configuration": {
                "id": "reserved",
                "blueprint": {
                  "conf": {
                    "disk": {
                      "id": "mldatasets",
                      "paths": [
                        {
                          "src": "/aipnd_projects",
                          "dest": "/data/"
                        }
                      ]
                    },
                    "ports": [],
                    "allowGrade": false,
                    "allowSubmit": false,
                    "defaultPath": "/notebooks/aipnd-project/Image%20Classifier%20Project.ipynb"
                  },
                  "kind": "jupyter"
                },
                "workspaceId": "reserved"
              },
              "starter_files": null
            }
          ]
        },
        {
          "id": 527822,
          "key": "4db448a2-9b6c-4df8-9685-d905814bca04",
          "title": "Image Classifier - Part 2 - Command Line App",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "4db448a2-9b6c-4df8-9685-d905814bca04",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 527860,
              "key": "c4baffd3-2d70-41c6-8851-cfc1114d0c29",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "# Part 2 - Building the command line application\n\nNow that you've built and trained a deep neural network on the flower data set, it's time to convert it into an application that others can use. Your application should be a pair of Python scripts that run from the command line. For testing, you should use the checkpoint you saved in the first part.\n\n### Specifications\n\nThe project submission must include at least two files `train.py` and `predict.py`. The first file, `train.py`, will train a new network on a dataset and save the model as a checkpoint. The second file, `predict.py`, uses a trained network to predict the class for an input image. Feel free to create as many other files as you need. Our suggestion is to create a file just for functions and classes relating to the model and another one for utility functions like loading data and preprocessing images. **Make sure to include all files necessary to run `train.py` and `predict.py` in your submission.**\n\n* Train a new network on a data set with `train.py`\n  * Basic usage: `python train.py data_directory`\n  * Prints out training loss, validation loss, and validation accuracy as the network trains\n  * Options:\n    * Set directory to save checkpoints: `python train.py data_dir --save_dir save_directory`\n    * Choose architecture: `python train.py data_dir --arch \"vgg13\"`\n    * Set hyperparameters: `python train.py data_dir --learning_rate 0.01 --hidden_units 512 --epochs 20`\n    * Use GPU for training: `python train.py data_dir --gpu`\n\n* Predict flower name from an image with `predict.py` along with the probability of that name. That is, you'll pass in a single image `/path/to/image` and return the flower name and class probability.\n  * Basic usage: `python predict.py /path/to/image checkpoint`\n  * Options:\n    * Return top <span class='mathquill'>K</span> most likely classes: `python predict.py input checkpoint --top_k 3`\n    * Use a mapping of categories to real names: `python predict.py input checkpoint --category_names cat_to_name.json`\n    * Use GPU for inference: `python predict.py input checkpoint --gpu`\n\nThe best way to get the command line input into the scripts is with the [argparse module](https://docs.python.org/3/library/argparse.html) in the standard library. You can also find [a nice tutorial for argparse here](https://pymotw.com/3/argparse/). ",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 613884,
          "key": "2457f366-d634-482e-9504-3eced80d87ab",
          "title": "Image Classifier - Part 2 - Workspace",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "2457f366-d634-482e-9504-3eced80d87ab",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 613885,
              "key": "26eb14fb-aa5c-4f17-92c0-c1c67522ccc4",
              "title": null,
              "semantic_type": "WorkspaceAtom",
              "is_public": true,
              "workspace_id": "view0228105f",
              "pool_id": "webterminalgpu",
              "view_id": "77d1c0de-f94f-497a-8d15-19a787d422f7",
              "gpu_capable": true,
              "configuration": {
                "id": "reserved",
                "blueprint": {
                  "conf": {
                    "disk": {
                      "id": "mldatasets",
                      "paths": [
                        {
                          "src": "/aipnd_projects",
                          "dest": "/data/"
                        }
                      ]
                    },
                    "port": 3000,
                    "ports": [],
                    "userCode": "",
                    "openFiles": [
                      "/home/workspace/ImageClassifier/train.py",
                      "/home/workspace/ImageClassifier/predict.py"
                    ],
                    "showFiles": true,
                    "allowClose": true,
                    "showEditor": true,
                    "allowSubmit": false,
                    "terminalTitle": "BASH"
                  },
                  "kind": "generic"
                },
                "workspaceId": "reserved"
              },
              "starter_files": null
            }
          ]
        },
        {
          "id": 534782,
          "key": "b4162538-0215-4bd0-9357-5e1614028ccf",
          "title": "Rubric",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "b4162538-0215-4bd0-9357-5e1614028ccf",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 534840,
              "key": "cd7edf48-58ab-4df5-b3e6-7c97c16f8e8d",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "### Files submitted\n| **Criteria** | **Specification** |\n|----|--|\n| Submission Files   | The submission includes all required files.",
              "instructor_notes": ""
            },
            {
              "id": 534843,
              "key": "95e83b2e-b881-41fe-b8c8-736339a510eb",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "### Part 1 - Development Notebook\n\n| **Criteria** | **Specification** |\n|----|--|\n| Package Imports   | All the necessary packages and modules are imported in the first cell of the notebook\n|Training data augmentation | torchvision transforms are used to augment the training data with random scaling, rotations, mirroring, and/or cropping |\n| Data normalization| The training, validation, and testing data is appropriately cropped and normalized |\n| Data loading | The data for each set (train, validation, test) is loaded with torchvision's ImageFolder|\n| Data batching| The data for each set is loaded with torchvision's DataLoader|\n| Pretrained Network | A pretrained network such as VGG16 is loaded from torchvision.models and the parameters are frozen|\n| Feedforward Classifier | A new feedforward network is defined for use as a classifier using the features as input |\n| Training the network | The parameters of the feedforward classifier are appropriately trained, while the parameters of the feature network are left static|\n| Validation Loss and Accuracy | During training, the validation loss and accuracy are displayed |\n|Testing Accuracy | The network's accuracy is measured on the test data |\n| Saving the model| The trained model is saved as a checkpoint along with associated hyperparameters and the `class_to_idx` dictionary|\n| Loading checkpoints| There is a function that successfully loads a checkpoint and rebuilds the model|\n| Image Processing | The `process_image` function successfully converts a PIL image into an object that can be used as input to a trained model |\n| Class Prediction | The `predict` function successfully takes the path to an image and a checkpoint, then returns the top K most probably classes for that image |\n| Sanity Checking with matplotlib | A matplotlib figure is created displaying an image and its associated top 5 most probable classes with actual flower names |",
              "instructor_notes": ""
            },
            {
              "id": 534844,
              "key": "1cd72f56-df46-42c6-94fa-8712f0d8cc05",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "## Part 2 - Command Line Application\n\n| **Criteria** | **Specification** |\n|--|--|\n| Training a network | `train.py` successfully trains a new network on a dataset of images |\n|Training validation log | The training loss, validation loss, and validation accuracy are printed out as a network trains|\n| Model architecture | The training script allows users to choose from at least two different architectures available from torchvision.models |\n|Model hyperparameters | The training script allows users to set hyperparameters for learning rate, number of hidden units, and training epochs |\n| Training with GPU | The training script allows users to choose training the model on a GPU |\n| Predicting classes | The `predict.py` script successfully reads in an image and a checkpoint then prints the most likely image class and it's associated probability |\n|Top K classes | The `predict.py` script allows users to print out the top K classes along with associated probabilities |\n| Displaying class names | The `predict.py` script allows users to load a JSON file that maps the class values to other category names|\n| Predicting with GPU | The `predict.py` script allows users to use the GPU to calculate the predictions |",
              "instructor_notes": ""
            }
          ]
        }
      ]
    }
  },
  "_deprecated": [
    {
      "name": "non_google_url",
      "reason": "(2016/8/18) Not sure, ask i18n team for reason"
    },
    {
      "name": "non_google_url",
      "reason": "(2016/8/18) Not sure, ask i18n team for reason"
    },
    {
      "name": "non_google_url",
      "reason": "(2016/8/18) Not sure, ask i18n team for reason"
    },
    {
      "name": "non_google_url",
      "reason": "(2016/8/18) Not sure, ask i18n team for reason"
    },
    {
      "name": "non_google_url",
      "reason": "(2016/8/18) Not sure, ask i18n team for reason"
    },
    {
      "name": "non_google_url",
      "reason": "(2016/8/18) Not sure, ask i18n team for reason"
    },
    {
      "name": "non_google_url",
      "reason": "(2016/8/18) Not sure, ask i18n team for reason"
    },
    {
      "name": "non_google_url",
      "reason": "(2016/8/18) Not sure, ask i18n team for reason"
    }
  ]
}